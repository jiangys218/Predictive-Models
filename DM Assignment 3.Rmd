---
title: "DM Assignment 3"
author: "Yunshuang Jiang"
date: "1/28/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Part 1

1. Load data and pick categorical variables\

```{r}
library(dplyr)
German.3.Credit <- read.csv("~/Desktop/German-3.Credit.csv")
germancrd <- German.3.Credit %>% dplyr::select(c(2,7,15,18))
set.seed(101)
train.index <- sample(1:nrow(germancrd), size = 0.7 * nrow(germancrd))
```
&nbsp;
&nbsp;

2. Determine 2, 3, 4,...N class solutions.\

```{r}
library(poLCA)
library(MASS)
library(scatterplot3d)

f<-with(germancrd, cbind(Account.Balance, Value.Savings.Stocks,Concurrent.Credits,Occupation)~1)

for (i in 2:5) {
poLCA(f,germancrd[train.index, ],nclass=i,nrep=10,tol=.001,verbose=FALSE, graphs=TRUE, na.rm=TRUE)}

aic <- c()
for (i in 2:5) {
  aic[i] <- poLCA(f,germancrd[train.index, ],nclass=i,nrep=10,tol=.001,verbose=FALSE, graphs=FALSE, na.rm=TRUE)$aic
}
val <- data.frame(nclass=paste("nclass.", 2:5, sep = ""), aic = aic[-1])
val
```

Conclusion: Based on AIC and distribution of the classes, we choose class n = 3. Moreover, as shown in the graph, class n = 3 separate the sample into three classes where class 1 shares 40.5%, class 2 shares 49%, and class 3 shares 10.4%, which is more evenly splited as compared to class higher classes.\

&nbsp;
&nbsp;

3. Perform holdout validation of LCA.\

```{r}
LCA.3.Train <- poLCA(f,germancrd[train.index, ],nclass=3,nrep=10,tol=.001,verbose=FALSE, graphs=FALSE, na.rm=TRUE)

LCA.3.Test <- poLCA(f,germancrd[-train.index, ],nclass=3,nrep=10,tol=.001,verbose=FALSE, graphs=TRUE, na.rm=TRUE, probs.start=LCA.3.Train$probs.start)

LCA.3.Test$aic
LCA.3.Test$llik

```
&nbsp;
&nbsp;

4. Comment on goodness, stability, interprebility and adequacy of model solutions.\

As for the goodness, LCA models with class = 2, 3, 4, 5 resulted in approximately the same maximum loglikelihood BIC and AIC creterion, there for the three models have equal goodness of fit.\

For interprebility, as shown in the graph (in part 2), class n = 3 separate the sample into three classes where class 1 shares 40.5%, class 2 shares 49%, and class 3 shares 10.4%. More specifically, class 1 represents people with no checking account (account.balance =0), no concurrent credit (concurrent.credits =3), and skilled employee/officials (occupation=3). Class 2 represents people with 0-200DM (account.balance =2), no concurrent credit (concurrent.credits =3), and skilled employee/officials (occupation=3). Class 3 represents people with relatively lower account balance (account.bal=1 or 2), less than 100 DM (Value.Saving.Stocks =1), no concurrent credit (concurrent.credits =3), and skilled employee/officials (occupation=3).\

For adequacy of the model, since the AIC creterion is large for all classes, this might suggests that LCA solutions might not be the best solutions to approach this problem.\

&nbsp;
&nbsp;


5. Compare K-means solution in Asisgnment 2 with LCA solution.\

In LCA model, we used categorical features, and we classified the population into three classes by account balance,  occupation, value savings & stocks, and concurrent credit. Since the AIC for models with class 2-5 are relatively large, which suggest that LCA solution might not be a good classifier for this problem.\

In Kmeans solution, we used numerical features only, and we classified popultion into three classes based on the age, durations, and installment rate. The Kmeans and Komeans resulted in more evenly splitted class sizes than LCA models, and have a lower AIC value, hence, this might suggest that Kmeans or komeans might be a better classifier for this problem.\

&nbsp;
&nbsp;
&nbsp;
&nbsp;


Part 2\

1. Load data and seperate data by 70:30.\

```{r}
library(caret)
data("GermanCredit")
germancr <- GermanCredit[, 1:7]
set.seed(10101)
index.train <- sample(1:nrow(germancr), size = 0.7 * nrow(germancr))
```
&nbsp;
&nbsp;

2. Perform PCA.\

```{r}
pca <- prcomp(germancr[index.train, ], scale = TRUE)
pca
```
&nbsp;
&nbsp;

3. Create scre plot and select number of components you would like to retain.\

```{r}
plot(pca)
vaf <- (pca$sdev)^2 / sum((pca$sdev)^2)
vaf.cum <- c(vaf[1], rep(0, 6))
for (i in 2 : 7) { vaf.cum[i] <- vaf[i] + vaf.cum[i - 1] }
plot(1 : 7, vaf.cum, main = "Scree Plot for PCA Train", xlab = "Component", 
     ylab = "VAF", type = "l", col = "11")

```

Based on the scre plot, I would retain 4 component to reach 73.56%. \
&nbsp;
&nbsp;

4. Plot Component 1 versus Component 2/3/4. Interpret and name the components.\
```{r}
#Component 1 & 2
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)

biplot12 <- ggbiplot(pca, choices = c(1, 2), scale = 0)
biplot12
pca$rotation[, c(1, 2)]
```

PC1 explains 24% of the variance and PC2 explains 19.9% of the variance. \

From the biplot as well as the factor loadings, we can see:\

PC1 assigns similar equal negative weights on "Duration" and "Amount", slightly positive weight on "InstallmenRatePercentage", and nearly zero weights on "Age", "Residence Duration", "Number of Exisiting Credits", and "Number People Maintenance". \

PC2 assigns similar negative weights on "Residence Duration", "Age", "Number Existing Credits", slightly negative weight for "Number People Maintenance", and nearly zero weight on "Duration", Amount" and "Installment Rate Percentage". \

These descriptions indicate: \
1. Features "Duration" and "Amount" are negatively correlated in PC1. This represents people have shorter duration and less amount are likely to have higher credit amount. We conclude that PC1 roughly corresponds to Length of Account Details. \
2. Features "Residence Duration", "Age", and "Number Existing Credits" are negatively weighted in PC2, which suggests the older the applicant, the longer his/her residence duration, as well as the more exisiting credits him/her has, are likely lead to lower credit amount. Thereby PC2 roughly corresponds to Personal Conditions.\

&nbsp;
&nbsp;

```{r}
#Component 1 & 3
biplot13 <- ggbiplot(pca, choices = c(1, 3), scale = 0)
biplot13
pca$rotation[, c(1, 3)]
```


PC1 explains 24% of the variance and PC3 explains 16.6% of the variance.\

From the biplot as well as the factor loadings, we can see:\

PC3 assigns strongly negative weights on "Installment Rate Percentage", positive weight on "Number People Maintenance", slightly negative weight for "Duration" and "Residence Duration", and nearly zero weight on other factors. \

These descriptions indicate: \
"Installment Rate Percentage" is strongly negatively correlated to PC3 while "Number People Maintenance" is strongly positively correlated to PC3. This suggests that the lower the installment rate percentage and the more people who is reliable for the maintenance of the loan will tend to lead to higher credit. \

&nbsp;
&nbsp;

```{r}
#Component 1 & 4
biplot14 <- ggbiplot(pca, choices = c(1, 4), scale = 0)
biplot14
pca$rotation[, c(1, 4)]
```

PC1 explains 24% of the variance and PC4 explains 13.2% of the variance.\

From the biplot as well as the factor loadings, we can see:\

PC4 assigns strong positive weights on "Number Existing Credits", slightly negative weight on "Residence Duration", slightly positive weights on "Installment Rate Percentage", and nearly zero weight on other factors.\ 

These descriptions indicate:\
"Number Existing Credits" is strongly positively correlated to PC4 while "Residence Duration" is negatively correlated to PC4. This suggests that the more exisiting credit card, the more people who is reliable for the maintenance of the loan, and the short the residence duration will tend to lead to higher credit.\

&nbsp;
&nbsp;


5. Show component loadings are orthogonal.\

```{r}
round(t(pca$rotation[,1:4]) %*% pca$rotation[,1:4],2)
```

The non-diagonal elements are nearly 0, hence we conclude that the component loadings are orthogonal.\
&nbsp;
&nbsp;

6. Show component scores are orthognal.\
```{r}
round(t(pca$x[,1:4]) %*% pca$x[,1:4],2)
```

The non-diagonal elements are nearly 0, hence we conclude that the component scores are orthogonal.\
&nbsp;
&nbsp;


7. Perform holdout validation of PCA.\
(i)\
```{r}
pcapred <- predict(pca, newdata = scale(germancr[-index.train, ]))
```

(ii)\
```{r}
dat <- as.vector(pcapred[,1:4] %*% t(pca$rotation)[1:4, ])
```
&nbsp;
&nbsp;

8. Compute VAF for holdout sample.

```{r}
cor(as.vector(scale(germancr[-index.train, ])), dat)
```
&nbsp;
&nbsp;

9. Rotate the component loadings using varimax rotation.

```{r}
pca$rotation

varimax(pca$rotation)
```

Comment: We can see that some of the factors have different weights. For instance, PC1 as in pca.rotation have a strong negative weight on Duration while in rotmat "Duration" has a strong positive weight. This change the interpretation for this component to people with longer duration are likely to have high credit amount, which makes more sense based on our intuition.\

&nbsp;
&nbsp;

10. Plot rotated loadings 1 vs. 2/3.\

```{r}
biplot(x = as.matrix(pca$x[,1:2]), y = as.matrix(varimax(pca$rotation)$rotmat[,1:2]))

biplot(x = as.matrix(pca$x[,c(1,3)]), y = as.matrix(varimax(pca$rotation)$rotmat[,c(1, 3)]))

```

Conclusion: I think Principal Components reduced our data by a decent amount. By keeping only 4PCs, we can still maintain 76% of the VAF. Having 4 components is easier to interpret our data and drive insight, hence, I like this solution.\


